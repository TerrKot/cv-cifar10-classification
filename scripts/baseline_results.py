#!/usr/bin/env python3
"""
Baseline —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
"""

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import numpy as np
import time
import os
import sys

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from models.simply_cnn import SimpleCNN, count_parameters

def test_baseline_model():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ–æ–±—É—á–µ–Ω–Ω–æ–π –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏"""
    
    print("üß™ BASELINE –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ï–û–ë–£–ß–ï–ù–ù–û–ô –ú–û–î–ï–õ–ò")
    print("=" * 60)
    
    # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
    model = SimpleCNN(num_classes=10).to(device)
    total_params = count_parameters(model)
    print(f"–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: SimpleCNN")
    print(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")
    
    # –°–æ–∑–¥–∞–µ–º DataLoader
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    
    test_dataset = torchvision.datasets.CIFAR10(
        root='./data', train=False, download=True, transform=transform
    )
    
    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)
    
    print(f"–¢–µ—Å—Ç–æ–≤—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {len(test_dataset):,}")
    print(f"–¢–µ—Å—Ç–æ–≤—ã—Ö –±–∞—Ç—á–µ–π: {len(test_loader)}")
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    print(f"\nüîç –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ù–ï–û–ë–£–ß–ï–ù–ù–û–ô –ú–û–î–ï–õ–ò...")
    
    model.eval()
    correct = 0
    total = 0
    batch_accuracies = []
    batch_times = []
    
    start_time = time.time()
    
    with torch.no_grad():
        for batch_idx, (data, target) in enumerate(test_loader):
            batch_start = time.time()
            
            data, target = data.to(device), target.to(device)
            
            # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥
            output = model(data)
            _, predicted = torch.max(output.data, 1)
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            total += target.size(0)
            correct += (predicted == target).sum().item()
            
            batch_correct = (predicted == target).sum().item()
            batch_total = target.size(0)
            batch_acc = 100. * batch_correct / batch_total
            batch_accuracies.append(batch_acc)
            
            batch_time = time.time() - batch_start
            batch_times.append(batch_time)
            
            # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 2 –±–∞—Ç—á–∞
            if (batch_idx + 1) % 2 == 0 or batch_idx == 0:
                print(f"  –ë–∞—Ç—á {batch_idx + 1:2d}: {batch_acc:6.1f}% "
                      f"({batch_correct:3d}/{batch_total:3d}) "
                      f"–≤—Ä–µ–º—è: {batch_time*1000:.1f}ms")
    
    total_time = time.time() - start_time
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    overall_accuracy = 100. * correct / total
    avg_batch_accuracy = np.mean(batch_accuracies)
    avg_batch_time = np.mean(batch_times)
    std_batch_time = np.std(batch_times)
    
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    print(f"–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –±–∞—Ç—á–µ–π: {len(test_loader)}")
    print(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {total:,}")
    print(f"–ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {correct:,}")
    print(f"–°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ –±–∞—Ç—á–∞–º: {avg_batch_accuracy:.2f}%")
    print(f"–û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {overall_accuracy:.2f}%")
    print(f"–û–±—â–µ–µ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {total_time:.2f} —Å–µ–∫")
    print(f"–°—Ä–µ–¥–Ω–∏–π time –Ω–∞ –±–∞—Ç—á: {avg_batch_time*1000:.2f}ms")
    print(f"–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {std_batch_time*1000:.2f}ms")
    print(f"–°–∫–æ—Ä–æ—Å—Ç—å: {total/avg_batch_time:.0f} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π/—Å–µ–∫")
    
    # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –±–∞—Ç—á–∞–º
    print(f"\nüìà –¢–û–ß–ù–û–°–¢–¨ –ü–û –ë–ê–¢–ß–ê–ú:")
    for i, acc in enumerate(batch_accuracies):
        print(f"–ë–∞—Ç—á {i+1:2d}: {acc:6.1f}%")
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(f"\nüîç –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
    
    # –°–ª—É—á–∞–π–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –¥–ª—è 10 –∫–ª–∞—Å—Å–æ–≤
    random_accuracy = 100.0 / 10  # 10%
    print(f"–°–ª—É—á–∞–π–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å (10 –∫–ª–∞—Å—Å–æ–≤): {random_accuracy:.1f}%")
    
    if overall_accuracy < random_accuracy * 0.5:
        print(f"‚ùå –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö—É–∂–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞")
    elif overall_accuracy < random_accuracy * 1.5:
        print(f"‚ö†Ô∏è  –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ –∫–∞–∫ —Å–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä")
    else:
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –æ–±—É—á–µ–Ω–∏—è")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
    if max(batch_accuracies) - min(batch_accuracies) > 50:
        print(f"‚ö†Ô∏è  –ë–æ–ª—å—à–æ–π —Ä–∞–∑–±—Ä–æ—Å —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ –±–∞—Ç—á–∞–º (–≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å)")
    else:
        print(f"‚úÖ –°—Ç–∞–±–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –ø–æ –±–∞—Ç—á–∞–º")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(f"\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í...")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    os.makedirs('results/5_epochs', exist_ok=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
    filename = 'results/5_epochs/baseline_results.txt'
    
    with open(filename, 'w', encoding='utf-8') as f:
        f.write("–ë–ê–ó–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ CNN –î–û –û–ë–£–ß–ï–ù–ò–Ø\n")
        f.write("=" * 50 + "\n\n")
        
        f.write(f"–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: SimpleCNN\n")
        f.write(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}\n")
        f.write(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\n\n")
        
        f.write("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:\n")
        f.write(f"–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –±–∞—Ç—á–µ–π: {len(test_loader)}\n")
        f.write(f"–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {total:,}\n")
        f.write(f"–°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ –±–∞—Ç—á–∞–º: {avg_batch_accuracy:.2f}%\n")
        f.write(f"–û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {overall_accuracy:.2f}%\n\n")
        
        f.write("–¢–û–ß–ù–û–°–¢–¨ –ü–û –ë–ê–¢–ß–ê–ú:\n")
        for i, acc in enumerate(batch_accuracies):
            f.write(f"–ë–∞—Ç—á {i+1:2d}: {acc:6.1f}%\n")
        
        f.write(f"\n–í–´–í–û–î: –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—É—é —Ç–æ—á–Ω–æ—Å—Ç—å ~{overall_accuracy:.1f}% ")
        f.write(f"(–æ–∂–∏–¥–∞–µ–º–æ –¥–ª—è –Ω–µ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏). –ì–æ—Ç–æ–≤–∞ –∫ –æ–±—É—á–µ–Ω–∏—é.\n")
    
    print(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {filename}")
    
    # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
    print(f"üìä –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞...")
    
    import matplotlib.pyplot as plt
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø–æ –±–∞—Ç—á–∞–º
    batch_indices = list(range(1, len(batch_accuracies) + 1))
    ax1.plot(batch_indices, batch_accuracies, 'b-', linewidth=2, marker='o')
    ax1.axhline(y=random_accuracy, color='r', linestyle='--', 
                label=f'–°–ª—É—á–∞–π–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å ({random_accuracy:.1f}%)')
    ax1.set_xlabel('–ù–æ–º–µ—Ä –±–∞—Ç—á–∞')
    ax1.set_ylabel('–¢–æ—á–Ω–æ—Å—Ç—å (%)')
    ax1.set_title('–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –±–∞—Ç—á–∞–º (–Ω–µ–æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_ylim(0, 100)
    
    # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–∞—Ç—á–µ–π
    ax2.hist(batch_times, bins=10, alpha=0.7, color='green', edgecolor='black')
    ax2.axvline(x=avg_batch_time, color='r', linestyle='--', 
                label=f'–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è ({avg_batch_time*1000:.1f}ms)')
    ax2.set_xlabel('–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –±–∞—Ç—á–∞ (—Å–µ–∫)')
    ax2.set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π')
    ax2.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('results/5_epochs/baseline_test_results.png', dpi=150, bbox_inches='tight')
    plt.show()
    
    print(f"‚úÖ –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ results/5_epochs/baseline_test_results.png")
    
    print(f"\nüéâ BASELINE –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print(f"–°–æ–∑–¥–∞–Ω—ã —Ñ–∞–π–ª—ã:")
    print(f"  - {filename} (–æ—Ç—á–µ—Ç)")
    print(f"  - results/5_epochs/baseline_test_results.png (–≥—Ä–∞—Ñ–∏–∫)")
    
    return overall_accuracy

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    try:
        accuracy = test_baseline_model()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–∑—É–º–Ω—ã–µ
        if accuracy < 5 or accuracy > 20:
            print(f"\n‚ö†Ô∏è  –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy:.2f}%")
            print("–û–∂–∏–¥–∞–µ—Ç—Å—è ~10% –¥–ª—è –Ω–µ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
